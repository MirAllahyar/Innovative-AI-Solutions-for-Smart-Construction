{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, LeakyReLU, Flatten, Reshape, BatchNormalization, Input, UpSampling2D, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from IPython.display import display, HTML\n"
      ],
      "metadata": {
        "id": "EQ6xW9QI5RtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Dense, Conv2D, UpSampling2D, LeakyReLU, Flatten, Reshape, BatchNormalization, Input, Activation)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ---------------------------\n",
        "# Mount Google Drive\n",
        "# ---------------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset Loader\n",
        "# ---------------------------\n",
        "def load_dataset(image_folder, target_size=(224, 224)):\n",
        "    image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "        img = img_to_array(img) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/House_Data_2'\n",
        "dataset = load_dataset(dataset_path)\n",
        "print(f\"Loaded dataset with {dataset.shape[0]} images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePZ8zHdk5N-O",
        "outputId": "e991ddda-a562-44d0-cd64-bf0502ef0139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loaded dataset with 3695 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    latent_input = Input(shape=(latent_dim,))\n",
        "\n",
        "    # Mapping Network\n",
        "    x = Dense(128)(latent_input)\n",
        "    for _ in range(7):\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Dense(128)(x)\n",
        "\n",
        "    # Start with low-resolution (4x4)\n",
        "    x = Dense(4 * 4 * 512)(latent_input)\n",
        "    x = Reshape((4, 4, 512))(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Progressive Growing\n",
        "    filters = [512, 256, 128, 64]\n",
        "    resolutions = [8, 16, 32, 64]  # Correct target resolutions\n",
        "    for f, res in zip(filters, resolutions):\n",
        "        x = UpSampling2D()(x)  # Double resolution\n",
        "        x = Conv2D(f, kernel_size=3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        print(f\"Current resolution: {res}x{res}\")\n",
        "\n",
        "    # Final Adjustment to 224x224\n",
        "    # Scale from 64x64 to 224x224\n",
        "    x = UpSampling2D(size=(3, 3))(x)  # Scale directly to 192x192\n",
        "    x = Conv2D(3, kernel_size=3, padding=\"same\", activation=\"tanh\")(x)\n",
        "\n",
        "    # Final 224x224 adjustment using Lambda layer\n",
        "    x = Lambda(lambda img: tf.image.resize(img, size=(224, 224)))(x)\n",
        "\n",
        "    model = Model(latent_input, x, name=\"Generator\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fw8acSmIFAWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "6ytS_nq1z0qO",
        "outputId": "d4c7db88-5a76-48c5-d33f-96093ef2208b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<button onclick=\"google.colab.kernel.invokeFunction('stop_training', [], {})\">Stop Training</button>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current resolution: 8x8\n",
            "Current resolution: 16x16\n",
            "Current resolution: 32x32\n",
            "Current resolution: 64x64\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ---------------------------\n",
        "# StyleGAN-Inspired Generator\n",
        "# ---------------------------\n",
        "# ---------------------------\n",
        "# Deep CNN-Based Discriminator\n",
        "# ---------------------------\n",
        "def build_discriminator(image_shape):\n",
        "    img_input = Input(shape=image_shape)\n",
        "\n",
        "    # Downsampling blocks\n",
        "    filters = [64, 128, 256, 512, 1024]\n",
        "    x = img_input\n",
        "    for f in filters:\n",
        "        x = Conv2D(f, kernel_size=4, strides=2, padding=\"same\")(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    # Final classification\n",
        "    x = Flatten()(x)\n",
        "    validity = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(img_input, validity, name=\"Discriminator\")\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# GAN Combined Model\n",
        "# ---------------------------\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    latent_input = Input(shape=(latent_dim,))\n",
        "    generated_img = generator(latent_input)\n",
        "    validity = discriminator(generated_img)\n",
        "    model = Model(latent_input, validity, name=\"GAN\")\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Training Functionality\n",
        "# ---------------------------\n",
        "stop_training_flag = False\n",
        "\n",
        "def save_models(generator, discriminator, epoch, path=\"/content/drive/MyDrive/GAN_Checkpoints\"):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    generator.save(os.path.join(path, f\"generator_epoch_{epoch}.h5\"))\n",
        "    discriminator.save(os.path.join(path, f\"discriminator_epoch_{epoch}.h5\"))\n",
        "    generator.save_weights(os.path.join(path, f\"generator_weights_epoch_{epoch}.h5\"))\n",
        "    discriminator.save_weights(os.path.join(path, f\"discriminator_weights_epoch_{epoch}.h5\"))\n",
        "\n",
        "def generate_and_save_images(generator, epoch, latent_dim, save_dir=\"/content/drive/MyDrive/GAN_Results\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    noise = np.random.normal(0, 1, (16, latent_dim))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = (generated_images + 1) * 127.5  # Rescale to [0, 255]\n",
        "    generated_images = generated_images.astype(np.uint8)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(generated_images[i])\n",
        "        ax.axis('off')\n",
        "    plt.savefig(os.path.join(save_dir, f\"epoch_{epoch}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def stop_training():\n",
        "    global stop_training_flag\n",
        "    stop_training_flag = True\n",
        "    print(\"Training will stop after this epoch.\")\n",
        "\n",
        "def train_gan(generator, discriminator, gan, dataset, epochs, batch_size, latent_dim):\n",
        "    global stop_training_flag\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        if stop_training_flag:\n",
        "            break\n",
        "\n",
        "        # Train Discriminator\n",
        "        for _ in range(batch_size):\n",
        "            idx = np.random.randint(0, dataset.shape[0], batch_size)\n",
        "            real_imgs = dataset[idx]\n",
        "            real_labels = np.ones((batch_size, 1))\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            fake_imgs = generator.predict(noise)\n",
        "            fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(real_imgs, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_labels)\n",
        "            d_loss = [\n",
        "                0.5 * (d_loss_real[0] + d_loss_fake[0]),  # Average loss\n",
        "                0.5 * (d_loss_real[1] + d_loss_fake[1])   # Average accuracy\n",
        "            ]\n",
        "\n",
        "        # Train Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        valid_labels = np.ones((batch_size, 1))\n",
        "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Extract g_loss value if it is a tensor or list\n",
        "        if isinstance(g_loss, (list, tuple)):\n",
        "            g_loss = g_loss[0]  # Take the first element if it’s a list/tuple\n",
        "        elif hasattr(g_loss, \"numpy\"):\n",
        "            g_loss = g_loss.numpy()  # Convert to NumPy if it’s a tensor\n",
        "\n",
        "        # Log progress\n",
        "        print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]:.4f} | D accuracy: {100 * d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
        "\n",
        "        # Save generated images and models at intervals\n",
        "        if epoch % 100 == 0 or epoch == epochs:\n",
        "            generate_and_save_images(generator, epoch, latent_dim)\n",
        "            save_models(generator, discriminator, epoch)\n",
        "\n",
        "    if stop_training_flag:\n",
        "        print(\"Training stopped by user.\")\n",
        "    save_models(generator, discriminator, \"final\")\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Add Stop Button\n",
        "# ---------------------------\n",
        "display(HTML(\"\"\"\n",
        "<button onclick=\"google.colab.kernel.invokeFunction('stop_training', [], {})\">Stop Training</button>\n",
        "\"\"\"))\n",
        "\n",
        "# ---------------------------\n",
        "# Parameters and Start Training\n",
        "# ---------------------------\n",
        "latent_dim = 128\n",
        "image_shape = (224, 224, 3)\n",
        "epochs = 5000\n",
        "batch_size = 32\n",
        "\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(image_shape)\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.999)\n",
        "discriminator.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "gan.compile(optimizer=optimizer, loss=\"binary_crossentropy\")\n",
        "\n",
        "train_gan(generator, discriminator, gan, dataset, epochs, batch_size, latent_dim)\n"
      ]
    }
  ]
}